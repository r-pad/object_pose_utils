{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import quat_math\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as scio\n",
    "from functools import partial\n",
    "from object_pose_utils.utils import to_np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshowCV(img, axis = False, show = True):\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if(show):\n",
    "        plt.show()\n",
    "    \n",
    "def imshow(img, axis = False, colorbar = False, show = True):\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    if(colorbar):\n",
    "        plt.colorbar()\n",
    "    if(show):\n",
    "        plt.show()\n",
    "    \n",
    "def torch2Img(img, show = True):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    disp_img = to_np(img)\n",
    "    if len(disp_img.shape) == 4:\n",
    "        disp_img = disp_img[0]\n",
    "    disp_img = disp_img.transpose((1,2,0))\n",
    "    disp_img = disp_img * std + mean\n",
    "    return disp_img\n",
    "    \n",
    "def imshowTorch(img, axis = False, show = True):\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "    disp_img = torch2Img(img)\n",
    "    plt.imshow(disp_img.astype(np.uint8))\n",
    "    if(show):\n",
    "        plt.show()\n",
    "\n",
    "def plotImageScatter(img, choose, show = True):\n",
    "    coords = np.unravel_index(choose, img.shape[:2])    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.astype(np.uint8))    \n",
    "    plt.scatter(coords[1], coords[0], 50)\n",
    "    #plt.colorbar()\n",
    "    if(show):\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = '/home/bokorn/data/ycb/debug/'\n",
    "object_id = 14\n",
    "mode = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.datasets.ycb_dataset import YcbDataset as YCBDataset\n",
    "from object_pose_utils.datasets.image_processing import ImageNormalizer\n",
    "from object_pose_utils.datasets.pose_dataset import OutputTypes as otypes\n",
    "\n",
    "output_format = [otypes.OBJECT_LABEL,\n",
    "                 otypes.QUATERNION, \n",
    "                 otypes.IMAGE_CROPPED, \n",
    "                 otypes.DEPTH_POINTS_MASKED_AND_INDEXES]\n",
    "\n",
    "ycb_dataset = YCBDataset(dataset_root, mode=mode, \n",
    "                         object_list = [object_id], \n",
    "                         output_data = output_format, \n",
    "                         postprocessors = [ImageNormalizer()],\n",
    "                         image_size = [640, 480], num_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.datasets.ycb_video_dataset import YcbVideoDataset as YCBVideoDataset\n",
    "\n",
    "dataset = YCBVideoDataset(ycb_dataset, \n",
    "                          interval = 4, \n",
    "                          video_len = 3)\n",
    "\n",
    "dataset.setVideoId('0000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\n",
      "['0000']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(dataset.getObjectIds())\n",
    "print(dataset.getVideoIds())\n",
    "print(len(dataset.index_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset.getItem(idx)\n",
    "trans = dataset.getCameraTransforms(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.utils.multi_view_utils import applyTransform, computeCameraTransform\n",
    "\n",
    "quats = []\n",
    "for mat, d in zip(trans, data):\n",
    "    quats.append(d[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.7850, -0.3913,  0.2590,  0.4044]),\n",
       " tensor([ 0.7841, -0.3918,  0.2614,  0.4041]),\n",
       " tensor([ 0.7843, -0.3931,  0.2619,  0.4021])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.78501582, -0.39128241,  0.25902703,  0.40441743]),\n",
       " array([ 0.78503512, -0.39129683,  0.25902578,  0.40436679]),\n",
       " array([ 0.78505671, -0.39129698,  0.25897794,  0.40435576])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quats_trans = applyTransform(quats, trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020641618571863796\n",
      "0.2910394930802486\n",
      "0.48652849477105786\n"
     ]
    }
   ],
   "source": [
    "from object_pose_utils.utils.pose_processing import quatAngularDiff\n",
    "q0 = to_np(data[0][1])\n",
    "for q, q_t in zip(quats, quat_trans):\n",
    "    quatAngularDiff(q0, q)*180/np.pi\n",
    "    print(, )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpy_kernel",
   "language": "python",
   "name": "bpy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
